{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYejfxynwC0O",
    "outputId": "9bf13304-4e6d-44e1-bd4b-7ca585467f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached grpcio-1.66.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached optree-0.12.1-cp311-cp311-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
      "Using cached tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.66.1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Downloading h5py-3.12.1-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.0/3.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.8/3.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.6/3.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 4.4 MB/s eta 0:00:00\n",
      "Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp311-cp311-win_amd64.whl (126 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.12.1 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.12.1 protobuf-4.25.5 rich-13.8.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0 werkzeug-3.0.4 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SecjX6OVpTeb",
    "outputId": "9b909981-2b75-4414-dd87-fb57c7f208b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OcCfKwTJqaCO",
    "outputId": "d32f0bc4-9c96-494f-b6ba-3a4159ac6f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-chess in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (1.999)\n",
      "Requirement already satisfied: anytree in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (2.12.1)\n",
      "Requirement already satisfied: loguru in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: chess<2,>=1 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from python-chess) (1.10.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from anytree) (1.16.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from loguru) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\programdata\\anaconda3\\envs\\env1\\lib\\site-packages (from loguru) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages (only needed in the first run, then can be skipped)\n",
    "!pip install python-chess anytree loguru PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_tILmn35ub5",
    "outputId": "5136295e-1900-459a-b60f-7798f1f56b76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import chess\n",
    "import chess.engine\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from loguru import logger\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "# Initialize logger for tracking\n",
    "logger.add(\"neurochess_log.log\", rotation=\"10 MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3A-DdbOifjx0",
    "outputId": "3212cefb-ea71-487b-c8c5-2ad0abd1300d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and selected.\n",
      "PyTorch can see the GPU.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available and selected.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available, using CPU instead.\")\n",
    "    import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"PyTorch can see the GPU.\")\n",
    "else:\n",
    "    print(\"PyTorch cannot see the GPU. Check CUDA installation.\")\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlxWjLORjB5J",
    "outputId": "c80f717d-459a-42f8-e008-9343caf3ea93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 27 22:32:44 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 561.09                 Driver Version: 561.09         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P0             16W /   94W |       0MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Tue_Feb_27_16:28:36_Pacific_Standard_Time_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.99\n",
      "Build cuda_12.4.r12.4/compiler.33961263_0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "potnaXkuWPLf",
    "outputId": "82c15ea7-6289-4311-d296-224cda4e1c45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n"
     ]
    }
   ],
   "source": [
    "# board.py\n",
    "class BoardManager:\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "\n",
    "    def make_move(self, move):\n",
    "        \"\"\"\n",
    "        Make a move on the board (if valid).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            chess_move = chess.Move.from_uci(move)\n",
    "            if chess_move in self.board.legal_moves:\n",
    "                self.board.push(chess_move)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid move: {move}\")\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "\n",
    "    def get_legal_moves(self):\n",
    "        return list(self.board.legal_moves)\n",
    "\n",
    "    def is_game_over(self):\n",
    "        return self.board.is_game_over()\n",
    "\n",
    "    def get_fen(self):\n",
    "        return self.board.fen()\n",
    "\n",
    "# Test the BoardManager\n",
    "board_manager = BoardManager()\n",
    "board_manager.make_move(\"e2e4\")\n",
    "print(board_manager.board)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JT_kvWetB-ia",
    "outputId": "f8599129-dd19-4ed5-cc97-1f3640f3ddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root node visits: 100\n"
     ]
    }
   ],
   "source": [
    "# mcts.py\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.visits = 0\n",
    "        self.value = 0\n",
    "\n",
    "    def expand(self):\n",
    "        for move in self.state.legal_moves:\n",
    "            child_state = self.state.copy()\n",
    "            child_state.push(move)\n",
    "            child_node = MCTSNode(child_state, parent=self)\n",
    "            self.children.append(child_node)\n",
    "\n",
    "    def select_best_child(self):\n",
    "        return max(self.children, key=lambda child: child.value / (child.visits + 1))\n",
    "\n",
    "    def backup(self, value):\n",
    "        self.value += value\n",
    "        self.visits += 1\n",
    "        if self.parent:\n",
    "            self.parent.backup(value)\n",
    "\n",
    "def monte_carlo_tree_search(root, num_simulations=100):\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        while node.children:\n",
    "            node = node.select_best_child()\n",
    "        node.expand()\n",
    "        value = random.random()  # Simulate a random value for simplicity\n",
    "        node.backup(value)\n",
    "\n",
    "# Test MCTS\n",
    "root_node = MCTSNode(board_manager.board)\n",
    "monte_carlo_tree_search(root_node)\n",
    "print(f\"Root node visits: {root_node.visits}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2-yOF0r6r0C",
    "outputId": "125b5c4a-d266-40d4-af09-81765f95e62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: 0.531063973903656\n"
     ]
    }
   ],
   "source": [
    "# neural_network.py\n",
    "class ChessNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(773, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.fc3(x))\n",
    "\n",
    "    def fen_to_input(self, fen):\n",
    "        # Convert FEN to a tensor input (simplified here)\n",
    "        input_vector = [0] * 773\n",
    "        return input_vector\n",
    "\n",
    "# Test the neural network\n",
    "model = ChessNet()\n",
    "example_input = torch.rand(1, 773)\n",
    "output = model(example_input)\n",
    "print(f\"Model output: {output.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g9iJUyD5WYgh"
   },
   "outputs": [],
   "source": [
    "# game_manager.py\n",
    "class GameManager:\n",
    "    def __init__(self, player_white='human', player_black='ai', use_mcts=False):\n",
    "        self.player_white = player_white\n",
    "        self.player_black = player_black\n",
    "        self.use_mcts = use_mcts\n",
    "        self.board_manager = BoardManager()\n",
    "\n",
    "    def play_game(self):\n",
    "        current_player = 'white'\n",
    "        while not self.board_manager.is_game_over():\n",
    "            print(self.board_manager.board)\n",
    "            if (current_player == 'white' and self.player_white == 'human') or \\\n",
    "               (current_player == 'black' and self.player_black == 'human'):\n",
    "                move = input(f\"{current_player}'s move: \")\n",
    "                self.board_manager.make_move(move)\n",
    "            else:\n",
    "                if self.use_mcts:\n",
    "                    root_node = MCTSNode(self.board_manager.board)\n",
    "                    monte_carlo_tree_search(root_node)\n",
    "                    best_move = root_node.select_best_child().state.peek()\n",
    "                    self.board_manager.make_move(best_move.uci())\n",
    "                else:\n",
    "                    legal_moves = self.board_manager.get_legal_moves()\n",
    "                    best_move = random.choice(legal_moves)\n",
    "                    self.board_manager.make_move(best_move.uci())\n",
    "\n",
    "            current_player = 'black' if current_player == 'white' else 'white'\n",
    "        print(\"Game over!\")\n",
    "        print(self.board_manager.board.result())\n",
    "\n",
    "# # Start a game (human vs AI with MCTS)\n",
    "# game_manager = GameManager(player_white='human', player_black='ai', use_mcts=True)\n",
    "# game_manager.play_game()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5tN5vHUWXt7",
    "outputId": "73631a47-19e2-4482-9cb5-51ec15fb7547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\env1\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:538: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\u001b[32m2024-09-27 22:33:10.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.23172686994075775\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# rl_training.py\n",
    "class RLTrainer:\n",
    "    def __init__(self, model, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = nn.MSELoss()\n",
    "        # Check for GPU availability and move model to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "            self.model.to(self.device)\n",
    "            print(\"Model moved to GPU.\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "            print(\"GPU not available, using CPU.\")\n",
    "\n",
    "    def train_step(self, board, reward):\n",
    "        self.optimizer.zero_grad()\n",
    "        # Changed: Call get_fen() to get the FEN string\n",
    "        board_tensor = torch.tensor(self.model.fen_to_input(board.get_fen()), dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # Move board_tensor to the device\n",
    "        board_tensor = board_tensor.to(self.device)\n",
    "\n",
    "        predicted_value = self.model(board_tensor)\n",
    "        # Fix: Move target_value to the same device as predicted_value\n",
    "        target_value = torch.tensor([reward], dtype=torch.float32).to(self.device)\n",
    "        loss = self.criterion(predicted_value, target_value)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        logger.info(f\"Training step completed with loss: {loss.item()}\")\n",
    "\n",
    "    def run_training(self, num_games=100):\n",
    "        \"\"\"\n",
    "        Runs the self-play and training loop for the specified number of games.\n",
    "\n",
    "        Args:\n",
    "            num_games (int): The number of self-play games to run for training.\n",
    "        \"\"\"\n",
    "        for game_num in range(num_games):\n",
    "            logger.info(f\"Starting training game {game_num + 1}/{num_games}\")\n",
    "\n",
    "            # 1. Self-play a game\n",
    "            game_manager = GameManager(player_white='ai', player_black='ai', use_mcts=True)\n",
    "            game_data = []  # List to store (state, reward) pairs\n",
    "\n",
    "            while not game_manager.board_manager.is_game_over():\n",
    "                root_node = MCTSNode(game_manager.board_manager.board)\n",
    "                monte_carlo_tree_search(root_node, num_simulations=100)  # Adjust num_simulations as needed\n",
    "                best_move = root_node.select_best_child().state.peek()\n",
    "                game_manager.board_manager.make_move(best_move.uci())\n",
    "\n",
    "                # Store the current state and a temporary reward (0 for now)\n",
    "                game_data.append(game_manager.board_manager.board.fen())\n",
    "\n",
    "            # Assign final rewards based on game outcome\n",
    "            game_result = game_manager.board_manager.board.result()\n",
    "            if game_result == \"1-0\":  # White wins\n",
    "                rewards = [1 if i % 2 == 0 else -1 for i in range(len(game_data))]\n",
    "            elif game_result == \"0-1\":  # Black wins\n",
    "                rewards = [-1 if i % 2 == 0 else 1 for i in range(len(game_data))]\n",
    "            else:  # Draw\n",
    "                rewards = [0] * len(game_data)\n",
    "\n",
    "            # 2. Train the model on the game data\n",
    "            for (state_fen, reward) in zip(game_data, rewards):\n",
    "                board = BoardManager()  # Create a temporary board to load the state\n",
    "                board.board.set_fen(state_fen)\n",
    "                self.train_step(board, reward)\n",
    "\n",
    "            logger.info(f\"Training game {game_num + 1}/{num_games} completed.\")\n",
    "\n",
    "        logger.info(\"Training completed successfully.\")\n",
    "# Setup training\n",
    "model = ChessNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = RLTrainer(model, optimizer)\n",
    "\n",
    "# Example training step\n",
    "reward = 1.0\n",
    "trainer.train_step(board_manager, reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IH38u_orWaJO",
    "outputId": "a7615ebf-8f26-4ed4-a345-5305e5861032"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-27 22:33:35.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 1/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2718919813632965\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.27161991596221924\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.27036887407302856\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2686529755592346\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.26666542887687683\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2644965648651123\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.26218923926353455\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.25976336002349854\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2572918236255646\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2547764778137207\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.25215426087379456\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.249424010515213\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.24663299322128296\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.24369299411773682\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.24068082869052887\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.23754361271858215\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.23427607119083405\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.23088578879833221\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2274511307477951\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.2240130454301834\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.22046957910060883\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.21674296259880066\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.21282580494880676\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 1/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:44.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 2/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.20871354639530182\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.20440267026424408\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.19989043474197388\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.19517554342746735\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.19026657938957214\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.18513859808444977\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.1797797679901123\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.1742149442434311\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.16845516860485077\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.1625097393989563\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.1563420444726944\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.1499943733215332\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.14350351691246033\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.13689017295837402\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.1301811933517456\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.12340565770864487\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.11659492552280426\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.10978225618600845\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.10300263017416\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.09629211574792862\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.08968722820281982\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.08322424441576004\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.07693777233362198\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 2/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:33:53.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 3/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0708584263920784\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.06501800566911697\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.05944341793656349\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.054157357662916183\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.049175191670656204\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.04446517676115036\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.04007334262132645\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.03601013496518135\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.03227728605270386\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.028870202600955963\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.025779200717806816\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.022990508005023003\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.020487230271100998\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.01822987012565136\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.016215575858950615\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.014426556415855885\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.012843325734138489\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.011446159332990646\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.010215883143246174\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.009134269319474697\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.008184351027011871\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.007350561674684286\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.006618767976760864\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 3/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:01.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 4/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.005976294167339802\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.005411869380623102\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.004915516823530197\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.004478475544601679\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.004093075171113014\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.003752626944333315\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.003451322205364704\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0031841136515140533\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0029466303531080484\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0027350899763405323\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0025462203193455935\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0023771878331899643\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.002225542673841119\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0020891616586595774\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.001966203795745969\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.001855074311606586\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0017543862340971828\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0016629345482215285\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0015796688385307789\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.001503671403042972\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0014341415371745825\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0013703779550269246\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0013117663329467177\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 4/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:09.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 5/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0012577647576108575\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0012078993022441864\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0011617502896115184\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0011189461220055819\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0010791611857712269\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.001042103860527277\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.001007515238597989\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0009751689503900707\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0009448579512536526\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0009164006332866848\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0008896341896615922\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.000864412693772465\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0008406043634749949\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0008180929580703378\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0007967722485773265\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0007765466580167413\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0007573304465040565\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0007390459068119526\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0007216226658783853\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0007049975101836026\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006891116499900818\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006739139789715409\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006593560101464391\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 5/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:17.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 6/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006453949608840048\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006319901440292597\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006191058782860637\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0006067094509489834\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005947694880887866\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005832594470120966\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005721528432331979\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005614269757643342\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005510590272024274\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005410303128883243\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.000531321857124567\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005219171871431172\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.000512799946591258\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0005039561656303704\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004953714087605476\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004870345874223858\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00047893309965729713\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004710559151135385\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00046339334221556783\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004559357766993344\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00044867454562336206\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004416010924614966\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00043470808304846287\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 6/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:25.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 7/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004279879212845117\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004214335640426725\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004150392487645149\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004087982524652034\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0004027052200399339\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003967544180341065\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003909412189386785\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003852605586871505\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003797078679781407\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003742790431715548\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003689693985506892\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00036377584910951555\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003586937382351607\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00035372033016756177\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00034885169588960707\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00034408498322591186\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00033941681613214314\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00033484474988654256\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003303656412754208\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003259766672272235\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00032167532481253147\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003174589655827731\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00031332546495832503\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 7/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 8/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00030927290208637714\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003052983374800533\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0003014003741554916\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002975763054564595\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002938247926067561\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.000290143012534827\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002865303831640631\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002829846052918583\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002795036125462502\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002760860079433769\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00027273083105683327\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00026943552074953914\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00026619969867169857\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00026302094920538366\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002598983410280198\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00025683038984425366\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002538164262659848\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00025085455854423344\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00024794318596832454\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002450822212267667\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00024226981622632593\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002395048359176144\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00023678643628954887\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 8/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:41.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 9/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002341135696042329\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00023148528998717666\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00022890027321409434\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00022635786444880068\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00022385695774573833\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00022139686916489154\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00021897665283177048\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002165952028008178\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00021425168961286545\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0002119459240930155\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00020967639284208417\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00020744271751027554\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00020524401043076068\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00020307973318267614\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00020094904175493866\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00019885106303263456\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00019678556418512017\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001947514247149229\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00019274848455097526\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00019077553588431329\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00018883257871493697\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00018691856530494988\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001850330736488104\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 9/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:49.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mStarting training game 10/10\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00018317556532565504\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00018134579295292497\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001795422867871821\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00017776584718376398\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.357\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001760147715685889\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001742894237395376\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001725887559587136\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00017091265181079507\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00016926036914810538\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00016763167514000088\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00016602588584646583\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00016444311768282205\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001628821191843599\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00016134310862980783\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00015982564946170896\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001583290140843019\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00015685317339375615\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00015539739979431033\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.0001539616205263883\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00015254544268827885\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00015114825509954244\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00014976995589677244\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_step\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mTraining step completed with loss: 0.00014841026859357953\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mTraining game 10/10 completed.\u001b[0m\n",
      "\u001b[32m2024-09-27 22:34:58.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_training\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mTraining completed successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# RL Self-play and training loop\n",
    "trainer.run_training(num_games=10)  # Train using 100 self-play games\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTEHQcN1WfAV",
    "outputId": "da8e03d1-e1dd-482d-b63a-748b52410bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# prompt: now i want to save trained model in nnue file\n",
    "\n",
    "import torch\n",
    "\n",
    "# Assuming 'model' is your trained ChessNet model\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "# You will need to implement a conversion function to transform\n",
    "# the PyTorch model weights into the NNUE format. This will involve\n",
    "# understanding the NNUE file structure and extracting relevant weights\n",
    "# from your model.\n",
    "\n",
    "# Example (pseudocode):\n",
    "# def convert_to_nnue(model_state_dict, output_file):\n",
    "#   \"\"\"Converts a PyTorch model to NNUE format.\"\"\"\n",
    "#   # Extract weights from the model state dictionary\n",
    "#   # ...\n",
    "#\n",
    "#   # Write the weights to the output file in NNUE format\n",
    "#   # ...\n",
    "\n",
    "# Convert the model to NNUE and save it\n",
    "# convert_to_nnue(model.state_dict(), 'trained_model.nnue')\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8B59t_vdFFs",
    "outputId": "758a64ad-c986-4b94-9150-db48f8e43c70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted and saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_12844\\3605913704.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('trained_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_nnue(model_state_dict, output_file):\n",
    "    \"\"\"Converts a PyTorch model to NNUE format.\"\"\"\n",
    "\n",
    "    # Extract weights and biases from the state dictionary\n",
    "    fc1_weight = model_state_dict['fc1.weight'].numpy().transpose()\n",
    "    fc1_bias = model_state_dict['fc1.bias'].numpy()\n",
    "    fc2_weight = model_state_dict['fc2.weight'].numpy().transpose()\n",
    "    fc2_bias = model_state_dict['fc2.bias'].numpy()\n",
    "    fc3_weight = model_state_dict['fc3.weight'].numpy().transpose()\n",
    "    fc3_bias = model_state_dict['fc3.bias'].numpy()\n",
    "\n",
    "    # Create the NNUE data structure\n",
    "    nnue_data = {\n",
    "        'input_layer': {\n",
    "            'weights': fc1_weight,\n",
    "            'biases': fc1_bias\n",
    "        },\n",
    "        'hidden_layer_1': {\n",
    "            'weights': fc2_weight,\n",
    "            'biases': fc2_bias\n",
    "        },\n",
    "        'output_layer': {\n",
    "            'weights': fc3_weight,\n",
    "            'biases': fc3_bias\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save the NNUE data to a file\n",
    "    with open(output_file, 'wb') as f:\n",
    "        np.savez(f, **nnue_data)\n",
    "\n",
    "# Load the PyTorch model\n",
    "model = ChessNet()\n",
    "model.load_state_dict(torch.load('trained_model.pth'))\n",
    "\n",
    "# Convert and save the model in NNUE format\n",
    "convert_to_nnue(model.state_dict(), 'trained_model.nnue')\n",
    "\n",
    "print(\"Model converted and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
